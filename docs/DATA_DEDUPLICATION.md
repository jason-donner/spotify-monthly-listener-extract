# Data Deduplication Guide

## Current Status âœ…
**Data is Clean**: As of June 25, 2025, the `spotify-monthly-listeners-master.json` file contains **5,582 clean entries with zero duplicates**. The bulletproof 3-layer duplicate prevention system is working perfectly.

## Recent Updates (June 25, 2025)
- **ğŸ›¡ï¸ Multi-Layer Duplicate Prevention**: Implemented enterprise-grade protection at 3 levels
- **ğŸ”§ Critical Date Format Fix**: Fixed date format mismatch that was causing duplicate creation
- **ğŸ§¹ Historical Data Cleanup**: Removed 15 duplicate entries from June 25, 2025 data
- **ğŸ” Enhanced Testing Tools**: Added comprehensive duplicate detection and prevention verification
- **ğŸ“Š Real-Time Prevention**: System now actively prevents and reports duplicate blocking

## Bulletproof Prevention System

### Three Layers of Protection

#### Layer 1: Pre-Scraping Check
**Location**: `scrape_filtered.py` and `scrape.py` â†’ `load_existing_listeners()`
**Function**: Checks master file for existing artist entries on target date
**Result**: Skips artists already scraped, shows "Skipping [Artist] - already scraped today"

#### Layer 2: Save-Time Validation  
**Location**: `append_to_master()` function in both scraping scripts
**Function**: Validates each entry before adding to master file using `(artist_id, date)` keys
**Result**: Prevents duplicates at save time, shows "Prevented duplicate: [Artist] for [Date]"

#### Layer 3: Data Integrity Tools
**Location**: `scripts/check_and_fix_duplicates.py` and `scripts/test_duplicate_prevention.py`
**Function**: Ongoing monitoring and cleanup of any edge cases
**Result**: Comprehensive data integrity verification and maintenance

### Critical Fix Applied (June 25, 2025)

**Problem Identified**: Date format mismatch in duplicate checking logic
- **Stored Data Format**: `YYYY-MM-DD` (e.g., "2025-06-25")
- **Previous Check Format**: `YYYYMMDD` (e.g., "20250625")
- **Result**: Duplicate prevention was failing due to format mismatch

**Fix Applied**: 
```python
# Before (BROKEN)
target_date_formatted = target_date.replace('-', '')  # Creates "20250625"
if entry.get('date') == target_date_formatted:  # Never matches "2025-06-25"

# After (FIXED)  
if entry.get('date') == target_date:  # Direct match with "2025-06-25"
```

## Overview
Before implementing duplicate protection, the scraping system could create multiple entries for the same artist on the same date. This guide covers how to identify and clean up these duplicates safely, and documents the prevention system now in place.

## Problem Description
**Symptoms:**
- Multiple entries for the same artist on the same date
- Identical or very similar monthly listener counts for duplicate entries
- Inflated data counts in the master file
- Potential inaccurate trending/growth calculations

**Root Cause:**
- Running scraping scripts multiple times on the same day before duplicate protection was implemented
- Manual data imports without deduplication
- System restarts or errors during scraping causing partial re-runs

## Solution: Deduplication Script

### Script Location
```
scripts/dedupe_listeners.py
```

### Usage
```bash
cd scripts
python dedupe_listeners.py
```

### What It Does
1. **Analysis Phase:**
   - Loads the master JSON file
   - Identifies duplicate artist-date combinations
   - Shows statistics and examples
   - Asks for user confirmation

2. **Backup Phase:**
   - Creates timestamped backup of original file
   - Ensures data safety before modifications

3. **Deduplication Phase:**
   - Keeps the latest entry for each artist-date combination
   - Removes earlier duplicates
   - Preserves chronological order

4. **Verification Phase:**
   - Confirms no duplicates remain
   - Shows cleanup statistics

### Deduplication Strategy
**Keep Latest Entry:** For each artist-date combination, keeps the entry that appears later in the file, as it's most likely the most recent/accurate data.

**Example:**
```json
// Before (duplicates)
[
  {"artist_id": "abc123", "date": "2025-06-25", "monthly_listeners": 1000, ...},
  {"artist_id": "abc123", "date": "2025-06-25", "monthly_listeners": 1000, ...}
]

// After (deduplicated)
[
  {"artist_id": "abc123", "date": "2025-06-25", "monthly_listeners": 1000, ...}
]
```

## Safety Features

### Automatic Backups
- Creates timestamped backup: `spotify-monthly-listeners-master.json.backup_YYYYMMDD_HHMMSS`
- Original data is preserved
- Easy rollback if needed

### User Confirmation
- Shows analysis results before proceeding
- Requires explicit user approval
- Can be cancelled at any time

### Data Validation
- Verifies cleanup was successful
- Confirms no duplicates remain
- Shows before/after statistics

## Manual Restoration
If you need to restore from backup:

```bash
# Navigate to data directory
cd data/results

# List available backups
ls -la *.backup_*

# Restore from specific backup
cp spotify-monthly-listeners-master.json.backup_YYYYMMDD_HHMMSS spotify-monthly-listeners-master.json
```

## Manual Cleanup Process (if needed)

In the rare case that duplicates are found after running the deduplication script, you can manually inspect and clean up the data:

1. **Load the Data**: Open `spotify-monthly-listeners-master.json` in a JSON editor or text editor.
2. **Find Duplicates**: Search for duplicate artist-date combinations. They will have the same `artist_id` and `date` values.
3. **Compare Entries**: For each duplicate group, compare the entries. Check fields like `monthly_listeners`, `followers`, and `artist_popularity`.
4. **Decide Which to Keep**: Generally, keep the entry with the highest `monthly_listeners`. If there's a tie, keep the one with the most recent data.
5. **Delete Duplicates**: Remove the duplicate entries, ensuring only the preferred one remains.
6. **Save the File**: After cleaning up duplicates, save the `spotify-monthly-listeners-master.json` file.
7. **Re-run the Deduplication Script**: To ensure no duplicates remain, re-run the `scripts/dedupe_listeners.py` script.

## Prevention

### Current Duplicate Protection
- Automatic duplicate detection in scraping scripts
- Date-based filtering to skip already-scraped artists
- `--allow-duplicates` flag for intentional re-scraping

### Best Practices
1. **Check for duplicates** before running scraping multiple times in a day
2. **Use today-only mode** for daily updates after initial setup
3. **Monitor data size** - sudden jumps may indicate duplicates
4. **Regular maintenance** - run deduplication monthly if needed

## Example Cleanup Session

```
ğŸ” Analyzing duplicates in master file...
ğŸ“Š Loaded 7,198 entries from master file

ğŸ“ˆ Duplicate Analysis Results:
   Total entries: 7,198
   Duplicate groups: 806
   Duplicate entries to remove: 806
   Clean entries after dedup: 6,392

ğŸ” Example duplicate groups:
   Waving on 20250625: 2 entries with listeners: [165, 165]
   Welcome the Plague Year on 20250625: 2 entries with listeners: [3602, 3602]
   Paint It Black on 20250625: 2 entries with listeners: [7699, 7699]

âš ï¸  This will remove 806 duplicate entries.
   Strategy: Keep the latest entry for each artist-date combination

ğŸ¤” Proceed with deduplication? (y/n): y

ğŸ’¾ Creating backup...
âœ… Backup created: ...backup_20250625_152834

ğŸ§¹ Deduplicating data...
âœ… Deduplicated: 7,198 â†’ 6,392 entries

ğŸ’¾ Saving cleaned data...
âœ… Saved cleaned data to spotify-monthly-listeners-master.json

ğŸ” Verifying cleanup...
âœ… Cleanup successful! No duplicates remain.
ğŸ“Š Final count: 6,392 clean entries

ğŸ“ˆ Cleanup Summary:
   Original entries: 7,198
   Removed duplicates: 806
   Final entries: 6,392
   Space saved: 11.2%
```

## Troubleshooting

### Common Issues

**"File not found" error:**
- Ensure you're running from the `scripts/` directory
- Check that the master JSON file exists in `../data/results/`

**"Permission denied" error:**
- Close any applications that might have the JSON file open
- Run with administrator privileges if needed

**Large file processing:**
- The script handles large files efficiently
- Progress is shown for large datasets
- Memory usage is optimized

### Performance Considerations
- **Memory Usage:** Loads entire file into memory - ensure sufficient RAM for large datasets
- **Processing Time:** Linear with file size - expect ~1-2 seconds per 1000 entries
- **Disk Space:** Backup requires additional space equal to original file size

## Integration with Web App

### Data Reload
After deduplication:
1. Restart the Flask web application to reload clean data
2. Check leaderboard and artist pages for accuracy
3. Verify that duplicate entries no longer appear in charts

### Impact on Features
- **Leaderboard:** More accurate growth calculations
- **Artist Pages:** Cleaner historical data
- **Search Results:** Consistent data points
- **Admin Panel:** Accurate statistics

## Scheduling Regular Cleanup

### Recommended Frequency
- **Monthly:** For active development/testing environments
- **Quarterly:** For stable production environments
- **As Needed:** When data size grows unexpectedly

### Automation Options
```bash
# Add to cron job (Linux/Mac)
0 2 1 * * cd /path/to/scripts && python dedupe_listeners.py < /dev/null

# Add to Windows Task Scheduler
# Run monthly at 2 AM on the 1st
```

## Related Files
- `scripts/dedupe_listeners.py` - Main deduplication script
- `data/results/spotify-monthly-listeners-master.json` - Master data file
- `scraping/scrape.py` - Now includes duplicate protection
- `scraping/scrape_filtered.py` - Filtered scraping with duplicate protection

## Recent Verification Record

### June 2025 - Data Integrity Check
**Date**: June 25, 2025  
**Action**: Comprehensive duplicate analysis  
**Tool**: `scripts/dedupe_listeners.py`

**Results**:
- âœ… **Total entries analyzed**: 6,392
- âœ… **Duplicate groups found**: 0
- âœ… **Duplicate entries**: 0  
- âœ… **Status**: Data is completely clean

**Conclusion**: The automatic duplicate prevention system implemented in the scraping scripts is working effectively. No historical duplicates remain in the dataset.

### Automatic Prevention System Status
**Implementation**: Active since June 2024  
**Location**: `scraping/scrape.py`, `scraping/scrape_filtered.py`  
**Features**:
- Checks existing data before scraping each artist
- Reports skipped duplicates in real-time
- Can be overridden with `--allow-duplicates` flag
- Integrated into web admin panel with checkbox control

## Testing and Verification Tools

### Duplicate Prevention Test
**Script**: `scripts/test_duplicate_prevention.py`
**Purpose**: Verify that duplicate prevention is working correctly
**Usage**:
```bash
python scripts/test_duplicate_prevention.py
```

**Sample Output**:
```
ğŸ› ï¸ Duplicate Prevention Test
==================================================
ğŸ§ª Testing duplicate prevention for date: 2025-06-25
Found 812 artists already scraped for 2025-06-25
âœ… Found 812 existing artist IDs for 2025-06-25
âœ… Duplicate prevention should work correctly!

ğŸ” Verifying date format consistency...
ğŸ“Š Found 1 different date format lengths: {10}
âœ… All dates use YYYY-MM-DD format (length 10) - consistency verified!

ğŸ“‹ Summary:
  - Duplicate prevention: âœ… Working
  - Date format consistency: âœ… Good
ğŸ‰ All tests passed! Duplicate prevention should work correctly.
```

### Duplicate Detection and Cleanup
**Script**: `scripts/check_and_fix_duplicates.py`
**Purpose**: Find and fix any existing duplicates in the master file
**Usage**:
```bash
python scripts/check_and_fix_duplicates.py
```

**Features**:
- Scans entire master file for duplicate `(artist_id, date)` combinations
- Shows detailed statistics about duplicates found
- Creates automatic backup before cleaning
- Keeps the latest entry for each duplicate set
- Provides comprehensive before/after reporting

**Sample Output**:
```
ğŸ” Checking for duplicates in master listeners file...
ğŸ“Š Total entries: 5597
ğŸš¨ Found 5 sets of duplicates:
  - It Looks Sad. (24M8W1AklCxyWTKjrJZDQ8) on 2025-06-25: 4 entries
  - Prawn (29yppqr48ptt5PmMQvawXs) on 2025-06-25: 4 entries
  [...]
ğŸ“ˆ Total duplicate entries to remove: 15

ğŸ‰ Deduplication complete!
  - Original entries: 5597
  - Cleaned entries: 5582
  - Removed duplicates: 15
```
