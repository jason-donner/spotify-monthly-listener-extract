# Data Deduplication Guide

## Current Status âœ…
**Data is Clean**: As of December 2024, the `spotify-monthly-listeners-master.json` file contains **no duplicate entries**. The automatic duplicate prevention system is working correctly.

## Overview
Before implementing duplicate protection, the scraping system could create multiple entries for the same artist on the same date. This guide covers how to identify and clean up these duplicates safely, and documents the prevention system now in place.

## Problem Description
**Symptoms:**
- Multiple entries for the same artist on the same date
- Identical or very similar monthly listener counts for duplicate entries
- Inflated data counts in the master file
- Potential inaccurate trending/growth calculations

**Root Cause:**
- Running scraping scripts multiple times on the same day before duplicate protection was implemented
- Manual data imports without deduplication
- System restarts or errors during scraping causing partial re-runs

## Solution: Deduplication Script

### Script Location
```
scripts/dedupe_listeners.py
```

### Usage
```bash
cd scripts
python dedupe_listeners.py
```

### What It Does
1. **Analysis Phase:**
   - Loads the master JSON file
   - Identifies duplicate artist-date combinations
   - Shows statistics and examples
   - Asks for user confirmation

2. **Backup Phase:**
   - Creates timestamped backup of original file
   - Ensures data safety before modifications

3. **Deduplication Phase:**
   - Keeps the latest entry for each artist-date combination
   - Removes earlier duplicates
   - Preserves chronological order

4. **Verification Phase:**
   - Confirms no duplicates remain
   - Shows cleanup statistics

### Deduplication Strategy
**Keep Latest Entry:** For each artist-date combination, keeps the entry that appears later in the file, as it's most likely the most recent/accurate data.

**Example:**
```json
// Before (duplicates)
[
  {"artist_id": "abc123", "date": "2025-06-25", "monthly_listeners": 1000, ...},
  {"artist_id": "abc123", "date": "2025-06-25", "monthly_listeners": 1000, ...}
]

// After (deduplicated)
[
  {"artist_id": "abc123", "date": "2025-06-25", "monthly_listeners": 1000, ...}
]
```

## Safety Features

### Automatic Backups
- Creates timestamped backup: `spotify-monthly-listeners-master.json.backup_YYYYMMDD_HHMMSS`
- Original data is preserved
- Easy rollback if needed

### User Confirmation
- Shows analysis results before proceeding
- Requires explicit user approval
- Can be cancelled at any time

### Data Validation
- Verifies cleanup was successful
- Confirms no duplicates remain
- Shows before/after statistics

## Manual Restoration
If you need to restore from backup:

```bash
# Navigate to data directory
cd data/results

# List available backups
ls -la *.backup_*

# Restore from specific backup
cp spotify-monthly-listeners-master.json.backup_YYYYMMDD_HHMMSS spotify-monthly-listeners-master.json
```

## Prevention

### Current Duplicate Protection
- Automatic duplicate detection in scraping scripts
- Date-based filtering to skip already-scraped artists
- `--allow-duplicates` flag for intentional re-scraping

### Best Practices
1. **Check for duplicates** before running scraping multiple times in a day
2. **Use today-only mode** for daily updates after initial setup
3. **Monitor data size** - sudden jumps may indicate duplicates
4. **Regular maintenance** - run deduplication monthly if needed

## Example Cleanup Session

```
ğŸ” Analyzing duplicates in master file...
ğŸ“Š Loaded 7,198 entries from master file

ğŸ“ˆ Duplicate Analysis Results:
   Total entries: 7,198
   Duplicate groups: 806
   Duplicate entries to remove: 806
   Clean entries after dedup: 6,392

ğŸ” Example duplicate groups:
   Waving on 20250625: 2 entries with listeners: [165, 165]
   Welcome the Plague Year on 20250625: 2 entries with listeners: [3602, 3602]
   Paint It Black on 20250625: 2 entries with listeners: [7699, 7699]

âš ï¸  This will remove 806 duplicate entries.
   Strategy: Keep the latest entry for each artist-date combination

ğŸ¤” Proceed with deduplication? (y/n): y

ğŸ’¾ Creating backup...
âœ… Backup created: ...backup_20250625_152834

ğŸ§¹ Deduplicating data...
âœ… Deduplicated: 7,198 â†’ 6,392 entries

ğŸ’¾ Saving cleaned data...
âœ… Saved cleaned data to spotify-monthly-listeners-master.json

ğŸ” Verifying cleanup...
âœ… Cleanup successful! No duplicates remain.
ğŸ“Š Final count: 6,392 clean entries

ğŸ“ˆ Cleanup Summary:
   Original entries: 7,198
   Removed duplicates: 806
   Final entries: 6,392
   Space saved: 11.2%
```

## Troubleshooting

### Common Issues

**"File not found" error:**
- Ensure you're running from the `scripts/` directory
- Check that the master JSON file exists in `../data/results/`

**"Permission denied" error:**
- Close any applications that might have the JSON file open
- Run with administrator privileges if needed

**Large file processing:**
- The script handles large files efficiently
- Progress is shown for large datasets
- Memory usage is optimized

### Performance Considerations
- **Memory Usage:** Loads entire file into memory - ensure sufficient RAM for large datasets
- **Processing Time:** Linear with file size - expect ~1-2 seconds per 1000 entries
- **Disk Space:** Backup requires additional space equal to original file size

## Integration with Web App

### Data Reload
After deduplication:
1. Restart the Flask web application to reload clean data
2. Check leaderboard and artist pages for accuracy
3. Verify that duplicate entries no longer appear in charts

### Impact on Features
- **Leaderboard:** More accurate growth calculations
- **Artist Pages:** Cleaner historical data
- **Search Results:** Consistent data points
- **Admin Panel:** Accurate statistics

## Scheduling Regular Cleanup

### Recommended Frequency
- **Monthly:** For active development/testing environments
- **Quarterly:** For stable production environments
- **As Needed:** When data size grows unexpectedly

### Automation Options
```bash
# Add to cron job (Linux/Mac)
0 2 1 * * cd /path/to/scripts && python dedupe_listeners.py < /dev/null

# Add to Windows Task Scheduler
# Run monthly at 2 AM on the 1st
```

## Related Files
- `scripts/dedupe_listeners.py` - Main deduplication script
- `data/results/spotify-monthly-listeners-master.json` - Master data file
- `scraping/scrape.py` - Now includes duplicate protection
- `scraping/scrape_filtered.py` - Filtered scraping with duplicate protection

## Recent Verification Record

### June 2025 - Data Integrity Check
**Date**: June 25, 2025  
**Action**: Comprehensive duplicate analysis  
**Tool**: `scripts/dedupe_listeners.py`

**Results**:
- âœ… **Total entries analyzed**: 6,392
- âœ… **Duplicate groups found**: 0
- âœ… **Duplicate entries**: 0  
- âœ… **Status**: Data is completely clean

**Conclusion**: The automatic duplicate prevention system implemented in the scraping scripts is working effectively. No historical duplicates remain in the dataset.

### Automatic Prevention System Status
**Implementation**: Active since June 2024  
**Location**: `scraping/scrape.py`, `scraping/scrape_filtered.py`  
**Features**:
- Checks existing data before scraping each artist
- Reports skipped duplicates in real-time
- Can be overridden with `--allow-duplicates` flag
- Integrated into web admin panel with checkbox control

---
